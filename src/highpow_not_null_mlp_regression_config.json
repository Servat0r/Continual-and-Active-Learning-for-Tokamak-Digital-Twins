{
  "general": {
    "task": "regression",
    "dtype": "float32",
    "num_campaigns": 10,
    "train_mb_size": 4096,
    "eval_mb_size": 1024,
    "train_epochs": 200
  },
  "dataset": {
    "pow_type": "highpow",
    "cluster_type": "tau_based",
    "dataset_type": "not_null",
    "input_columns": [
      "ane", "ate", "autor", "machtor", "x",
      "zeff", "gammae", "q", "smag", "alpha",
      "ani1", "ati0", "normni1", "ti_te0", "lognustar"
    ],
    "output_columns": ["efe", "efi", "pfe", "pfi"],
    "input_size": 15,
    "output_size": 4,
    "normalize_inputs": true,
    "normalize_outputs": false,
    "load_saved_final_data": true
  },
  "architecture": {
    "name": "saved",
    "model_folder": "highpow_mlp_256_2_efe_efi_pfe_pfi_8runs",
    "model_name": "model",
    "model_class_name": "MLP",
    "parameters": {
      "input_size": 15,
      "output_size": 4,
      "hidden_size": 256,
      "hidden_layers": 2,
      "drop_rate": 0.5
    }
  },
  "loss": {
    "name": "MSE",
    "parameters": {
      "reduction":  "mean"
    }
  },
  "optimizer": {
    "name": "Adam",
    "parameters": {
      "lr": 2e-3,
      "weight_decay": 1e-5
    }
  },
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "parameters": {
      "metric": "train_loss",
      "first_exp_only": false,
      "factor": 0.5,
      "patience": 11,
      "mode": "min",
      "threshold_mode": "abs",
      "threshold": 0.5,
      "min_lr": 1e-4
    }
  },
  "strategy": [
    {
      "name": "Naive",
      "extra_log_folder": "Base (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
      }
    },
    {
      "name": "FromScratchTraining",
      "extra_log_folder": "Base (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
      }
    },
    {
      "name": "PercentageReplay",
      "extra_log_folder": "Percentage 5% (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "mem_percentage": 0.05
      }
    },
    {
      "name": "PercentageReplay",
      "extra_log_folder": "Percentage 10% (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "mem_percentage": 0.1
      }
    },
    {
      "name": "Replay",
      "extra_log_folder": "Buffer 2000 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "mem_size": 2000
      }
    },
    {
      "name": "Replay",
      "extra_log_folder": "Buffer 10000 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "mem_size": 10000
      }
    },
    {
      "name": "EWC",
      "extra_log_folder": "Lambda 10 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "mode": "separate",
        "ewc_lambda": 10.0
      }
    },
    {
      "name": "EWC",
      "extra_log_folder": "Lambda 1 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "mode": "separate",
        "ewc_lambda": 1.0
      }
    },
    {
      "name": "EWC",
      "extra_log_folder": "Lambda 0.1 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "mode": "separate",
        "ewc_lambda": 0.1
      }
    },
    {
      "name": "EWCReplay",
      "extra_log_folder": "Lambda 10 Buffer 1000 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "mode": "separate",
        "ewc_lambda": 10.0,
        "mem_size": 1000
      }
    },
    {
      "name": "MAS",
      "extra_log_folder": "Lambda 10 Alpha 0,5 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "lambda_reg": 10.0,
        "alpha": 0.5
      }
    },
    {
      "name": "MAS",
      "extra_log_folder": "Lambda 1 Alpha 0,5 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "lambda_reg": 1.0,
        "alpha": 0.5
      }
    },
    {
      "name": "MAS",
      "extra_log_folder": "Lambda 10 Alpha 1,0 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "lambda_reg": 10.0,
        "alpha": 1.0
      }
    },
    {
      "name": "MASReplay",
      "extra_log_folder": "Lambda 10 Alpha 0,5 Buffer 1000 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "lambda_reg": 10.0,
        "alpha": 0.5,
        "mem_size": 1000
      }
    },
    {
      "name": "AGEM",
      "extra_log_folder": "Patterns 200 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "patterns_per_exp": 200
      }
    },
    {
      "name": "GEM",
      "extra_log_folder": "Patterns 100 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "patterns_per_exp": 100
      }
    },
    {
      "name": "GEM",
      "extra_log_folder": "Patterns 200 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "patterns_per_exp": 200
      }
    },
    {
      "name": "GEM",
      "extra_log_folder": "Patterns 400 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "patterns_per_exp": 400
      }
    },
    {
      "name": "GEM",
      "extra_log_folder": "Patterns 1000 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "patterns_per_exp": 1000
      }
    },
    {
      "name": "GEMReplay",
      "extra_log_folder": "Patterns 100 Buffer 1000 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "patterns_per_exp": 100,
        "mem_size": 1000
      }
    },
    {
      "name": "LFL",
      "extra_log_folder": "Lambda 0.1 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "lambda_e": 0.1
      }
    },
    {
      "name": "LFL",
      "extra_log_folder": "Lambda 1 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "lambda_e": 1.0
      }
    },
    {
      "name": "LFL",
      "extra_log_folder": "Lambda 10 (4096 batch size) (256 hidden size)",
      "ignore": false,
      "parameters": {
        "lambda_e": 10.0
      }
    },
    {
      "name": "SI",
      "extra_log_folder": "Lambda 10 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "si_lambda": 10.0
      }
    },
    {
      "name": "SI",
      "extra_log_folder": "Lambda 100 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "si_lambda": 100.0
      }
    },
    {
      "name": "SI",
      "extra_log_folder": "Lambda 1 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "si_lambda": 1.0
      }
    },
    {
      "name": "SI",
      "extra_log_folder": "Lambda 0.1 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "si_lambda": 0.1
      }
    },
    {
      "name": "GDumb",
      "extra_log_folder": "Buffer 2000 (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "mem_size": 2000
      }
    },
    {
      "name": "JointTraining",
      "extra_log_folder": "Base (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
        "eval_every": 0
      }
    },
    {
      "name": "Cumulative",
      "extra_log_folder": "Base (4096 batch size) (256 hidden size)",
      "ignore": true,
      "parameters": {
      }
    }
  ],
  "early_stopping": {
    "patience": 50,
    "delta": 0.1,
    "val_stream_name": "eval_stream",
    "min_epochs": 100
  },
  "validation_stream": {
    "val_stream": "eval_stream"
  },
  "start_model_saving": {
    "save_model": false,
    "saved_model_folder": "highpow_mlp_256_2_efe_efi_pfe_pfi_8runs",
    "saved_model_name": "model",
    "add_timestamp": false
  }
}